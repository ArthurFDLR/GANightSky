{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stylegan2-ada Custom Training.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurFDLR/GANightSky/blob/main/styleGAN2-ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPI5E5y0pujD"
      },
      "source": [
        "# StyleGan2-ADA in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI_i1MwgpzOD"
      },
      "source": [
        "StyleGAN2-ADA only work with Tensorflow 1. Run the next cell before anything else to make sure we’re using TF1 and not TF2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYAU7Wub3WW"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YcUMPQp6ipP"
      },
      "source": [
        "## Install [StyleGAN2-ADA Repository](https://github.com/NVlabs/stylegan2-ada) in your Google Drive\n",
        "\n",
        "First, mount your Drive to the Colab notebook: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxxYlEKI9Gis"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.mount(str(drive_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epV6TDzAjox1"
      },
      "source": [
        "Next, run this cell. If you’ve already installed the repository, it will skip the installation process and only check for updates. If you haven’t installed it, it will install all the necessary files. Beside, **in**, **out**, **datasets** and **training** folders are generated for data storage. Everything will be available on your Google Drive in the folder **StyleGAN2-ADA** even after closing this Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV"
      },
      "source": [
        "stylegan2_repo_url  = 'https://github.com/ArthurFDLR/stylegan2-ada' # Original repository: https://github.com/NVlabs/stylegan2-ada\n",
        "project_path        = drive_path / 'MyDrive' / 'StyleGAN2-ADA'\n",
        "stylegan2_repo_path = project_path / 'stylegan2-ada'\n",
        "\n",
        "# Create project folder if inexistant\n",
        "if not project_path.is_dir():\n",
        "    %mkdir \"{project_path}\"\n",
        "%cd \"{project_path}\"\n",
        "\n",
        "for dir in ['in', 'out', 'datasets', 'training']:\n",
        "    if not (project_path / dir).is_dir():\n",
        "        %mkdir {dir}\n",
        "if not (project_path / 'datasets' / 'source').is_dir():\n",
        "    %mkdir \"{project_path / 'datasets' / 'source'}\"\n",
        "\n",
        "# Download StyleGAN2-ada\n",
        "!git config --global user.name \"ArthurFDLR\"\n",
        "!git config --global user.email \"arthfind@gmail.com\"\n",
        "if stylegan2_repo_path.is_dir():\n",
        "    !git -C \"{stylegan2_repo_path}\" fetch origin\n",
        "    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n",
        "else:\n",
        "    !git clone {stylegan2_repo_url}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0A9ZNtferpk"
      },
      "source": [
        "## Generate image from pre-trained model\n",
        "\n",
        "You can now generate images using pre-trained networks. NVLab published some of their network pickles on [their website](https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/). You can also use your own model once it is trained (we will come to model training in a few cells)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnlrb9QzgaGp"
      },
      "source": [
        "%pip install opensimplex\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images --help "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQqYjeRsfYD2"
      },
      "source": [
        "from numpy import random\n",
        "seed_init = random.randint(10000)\n",
        "nbr_images = 2\n",
        "\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images \\\n",
        "    --outdir=\"{project_path / 'out'}\" --trunc=0.7 \\\n",
        "    --seeds={seed_init}-{seed_init+nbr_images-1} --create-grid \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yG1UyHXXqsO"
      },
      "source": [
        "## Latent space exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veceGR6QYA93"
      },
      "source": [
        "%pip install opensimplex\r\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --help "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjsN05ksZYZ7"
      },
      "source": [
        "from numpy import random\r\n",
        "walk_types = ['line', 'sphere', 'noiseloop', 'circularloop']\r\n",
        "latent_walk_path = project_path / 'out' / 'latent_walk'\r\n",
        "if not latent_walk_path.is_dir():\r\n",
        "    %mkdir \"{latent_walk_path}\"\r\n",
        "\r\n",
        "explored_network = '/content/drive/MyDrive/StyleGAN2-ADA/training/NightSky/00010-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000256.pkl'\r\n",
        "seeds = [519, 1343, 1431, 1535, 1599, 1764, 519] #[random.randint(10000) for  i in range(20)] \r\n",
        "print(\"Seeds:\", seeds)\r\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --network=\"{explored_network}\" \\\r\n",
        "    --outdir=\"{latent_walk_path}\" --trunc=0.7 --walk-type=\"{walk_types[2]}\" \\\r\n",
        "    --seeds={','.join(map(str, seeds))} --frames {len(seeds)*20}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti11YiPAiQpb"
      },
      "source": [
        "## Train a custom model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlV5HIEqiZvu"
      },
      "source": [
        "dataset_name = 'NightSky'\n",
        "datasets_path = project_path / 'datasets' / dataset_name\n",
        "training_path = project_path / 'training' / dataset_name\n",
        "\n",
        "if not datasets_path.is_dir():\n",
        "    print(\"Need to convert dataset to .tfrecords\")\n",
        "else:\n",
        "    print('Ready for training!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y1-tvr5617d"
      },
      "source": [
        "Large dataset might exceed Google Drive quota after a few training batches. Indeed, StyleGAN2 download datasets multiple times during training. You might have to import your dataset in the local storage session. However, large files cannot be copy/paste from Drive *(Input/Output error)*. \n",
        "\n",
        "To download your zipped dataset from your drive and unzip it in local machine, run this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQZGo4g5y7rh"
      },
      "source": [
        "local_dataset_path = content_path / 'dataset'\n",
        "if not local_dataset_path.is_dir():\n",
        "    %mkdir \"{local_dataset_path}\"\n",
        "    %cp -a \"{project_path / 'datasets' / 'source' / (dataset_name + '.zip')}\" \"{local_dataset_path}\"\n",
        "    print(\"Zip file imported\")\n",
        "else:\n",
        "    print('Allready imported')\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(str(local_dataset_path / (dataset_name + '.zip')), 'r') as zip_ref:\n",
        "    zip_ref.extractall(str(local_dataset_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeS9tDvt61VG"
      },
      "source": [
        "### Convert dataset to .tfrecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q58MJbckLUc"
      },
      "source": [
        "**Note: You only need to do this once per dataset. If you have already run this and are returning to conntinue training, skip these cells.**\n",
        "\n",
        "Next we need to convert our image dataset to a format that StyleGAN2-ADA can read from. There are two options here. You can upload your dataset directly to Colab (as a zipped file), or you can upload it to Drive directly and read it from there.\n",
        "\n",
        "Now that your image dataset is uploaded, we need to convert it to the `.tfrecords` format.\n",
        "\n",
        "Depending on the resolution of your images and how many you have, this can take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjH8kBDo3kFP"
      },
      "source": [
        "local_images_path = local_dataset_path / 'images'\n",
        "local_dataset_path /= 'tfr'\n",
        "\n",
        "if (local_dataset_path).is_dir():\n",
        "    print('\\N{Heavy Exclamation Mark Symbol} Dataset already created \\N{Heavy Exclamation Mark Symbol}')\n",
        "    print('Delete current dataset folder ({}) to regenerate tfrecords.'.format(local_dataset_path))\n",
        "else:\n",
        "    %mkdir \"{local_dataset_path}\"\n",
        "    !python \"{stylegan2_repo_path / 'dataset_tool.py'}\" create_from_images \\\n",
        "        \"{local_dataset_path}\" \"{local_images_path}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DvTupHzP2s_"
      },
      "source": [
        "### Launch training\n",
        "\n",
        "There are numerous arguments to tune the training of your model. To obtain nice results, you will certainly have to experiment. Here are the most popular options:\n",
        "\n",
        "\n",
        "*   *mirror:* Should the images be mirrored vertically?\n",
        "*   *mirrory:* Should the images be mirrored horizontally?\n",
        "*   *snap:* How often should the model generate image samples and a network pickle (.pkl file)?\n",
        "*   *resume:* Network pickle to resume training from?\n",
        "\n",
        "To see all the options, run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxu7CA0Qb1Yd"
      },
      "source": [
        "!python \"{stylegan2_repo_path / 'train.py'}\" --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOftFoyiDU3s"
      },
      "source": [
        "if not training_path.is_dir():\n",
        "    %mkdir \"{training_path}\"\n",
        "\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 2\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#augments\n",
        "augs = 'bgc'\n",
        "\n",
        "#resume_from = 'ffhq1024'\n",
        "resume_from = '/content/drive/MyDrive/StyleGAN2-ADA/training/NightSky/00009-tfr-mirror-auto1-bgc-resumecustom/network-snapshot-000112.pkl'\n",
        "\n",
        "!python \"{stylegan2_repo_path / 'train.py'}\" --outdir=\"{training_path}\" \\\n",
        "    --data=\"{local_dataset_path}\" --resume=\"{resume_from}\" \\\n",
        "    --snap={snapshot_count} --augpipe={augs} \\\n",
        "    --mirror={mirrored} --metrics={metric_list} #--dry-run #--mirrory={mirroredY}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZR4ireZE6JF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9878RlntrDp"
      },
      "source": [
        "## While you wait ...\n",
        "\n",
        "... learn more about StyleGAN2-ADA and Generative Adversarial Networks in general:\n",
        "\n",
        "*   [Karras, Tero, et al. _Analyzing and Improving the Image Quality of StyleGAN._ CVPR 2020.](https://arxiv.org/pdf/2006.06676.pdf): Paper published for the release of StyleGAN2-ADA.\n",
        "*   [Official implementation of StyleGAN2-ADA](https://github.com/NVlabs/stylegan2-ada)\n"
      ]
    }
  ]
}